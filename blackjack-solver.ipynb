{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48cfd596-81d5-403b-af8b-a3de8cf9ef02",
   "metadata": {},
   "source": [
    "# Blackjack Solver\n",
    "Shantanu Laghate, November 2024\n",
    "\n",
    "## Problem Definition\n",
    "Objective of the game:\n",
    "- obtain cards the sum of whose numerican values is as great as possible without exceeding 21.\n",
    "- All face cards count as 10, ace can count as either 1 or 11.\n",
    "- Player competes independently against dealer.\n",
    "\n",
    "Gameplay:\n",
    "- Game begins with two cards dealt to both dealer and player. One of dealer's cards is face up, other is face down.\n",
    "- If player has 21 immediately (Ace + 10), this is a natural and player wins unless dealer also has a natural in which case it's a draw\n",
    "- Otherwise, player has two actions:\n",
    "    + Hit (request additional card)\n",
    "        * If the player exceeds 21 (goes bust), he loses\n",
    "    + Stick (stop with current cards)\n",
    "        * After stick, it becomes the dealer's turn.\n",
    "- The dealer follows a fixed strategy without choice: stick on any sum 17 or greater, and hits otherwise. If dealer goes bust, player wins. \n",
    "- Final outcome decided by whose final sum is closer to 21.\n",
    "\n",
    "Assumption: cards are dealth from an infinite deck (with replacement), so that there is no advantage to keeping track of the cards already dealt. \n",
    "\n",
    "## Formulation as MDP\n",
    "We can formulate Blackjack as an episodic finite MDP. Each hand of Blackjack is an episode. \n",
    "- Rewards: +1, -1, 0 are given for winning, losing, and drawing. All rewards within a game are 0.\n",
    "- Actions: Hit or Stick\n",
    "- State: Three variables (Usable Ace, Player's cards and dealer's showing card)\n",
    "    + Usable ace: if player has ace that can be used as 11 without going bust.\n",
    "    + Current Sum (12-21) - since if the sum is 11 or lower the player will always hit, there is no decision to make. \n",
    "    + Dealer's one showing card (ace-10)\n",
    "    + Total 200 states\n",
    "\n",
    "\n",
    "## On-policy Monte Carlo Algorithm with Exploring Starts \n",
    "With a Monte Carlo method, we will simulate millions of hands of blackjack to find the optimal policy. We will estimate the Action-Value function, which is the expected return from a given state $s$, if the immediate following action is $a$. This estimate is given by $Q(s, a)$.\n",
    "\n",
    "Here is the pseudocode for the algorithm:\n",
    "```\n",
    "Initialize:\n",
    "    pi[s], arbitrarily for all s in S, a in A\n",
    "    Q[s, a] = 0 for all s in S, a in A\n",
    "    Count[s, a] = 0 for all s in S, a in A\n",
    "\n",
    "Loop infinitely (for each episode):\n",
    "    Choose S_0, A_0 randomly such that all pairs have probability > 0\n",
    "    Generate an episode from S_0, A_0 following pi: S_0, A_0, R_1, ..., S_T-1, A_T-1, R_T\n",
    "    G = 0\n",
    "    Loop for each step in the episode t = T-1, T-2, ..., 0:\n",
    "    G = gamma*G + R_{t+1}\n",
    "    Unless the pair (St, At) appears earlier in the episode:\n",
    "        Count[St, At] += 1\n",
    "        Q(St, At) = Q[St, At] + 1/Count[St, At]*(G - Q[St, At]) # incremental update algorithm\n",
    "        pi[St] = argmax_a Q[St, a]\n",
    "```\n",
    "\n",
    "## Representing State and Action Spaces, Policy\n",
    "Since there is no decision to be made when `current_sum < 12`, the indexing will correspond to `current_sum-12`.\n",
    "State is a `(usable_ace, current_sum, dealer_card)` tuple. Action is an enum between `HIT = 0 , STICK = 1`. The action-value function can then be represented by a 4d numpy array: `Q[usable_ace][current_sum][dealer_card][action]`. \n",
    "\n",
    "The policy can be represented as a 3d numpy array: `pi[usable_ace, current_sum][dealer_card] in {HIT, STICK}`. \n",
    "\n",
    "## Performing the Iteration \n",
    "To perform exploring starts, we first select a random state tuple, and random action for our S0, A0. Follow the policy `pi` until the player either goes bust or chooses `STICK`. If the player is not bust, iterate on the dealer until dealer sum is 17 or higher (or dealer goes bust). Finally, compare sums and delegate reward accordingly. All rewards until the last reward will be 0 in the episode. We will keep track of states, actions, and rewards for the entire episode as they are generated. The dealer iteration does not need to be kept track, only the final result is captured in the last reward. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f02a1599-543e-4b86-9a5a-f116c5aeccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum\n",
    "from typing import List, Tuple, Optional\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,  # Set default logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edadf87e-e124-4edf-aca4-72a213c10f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action(Enum):\n",
    "    HIT = 0\n",
    "    STICK = 1\n",
    "\n",
    "SUM_OFFSET = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04324147-0710-4994-9ba9-625fb94a29b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_card_value() -> Tuple[int, bool]:\n",
    "    # cards 1, 14, 27, 40 are aces\n",
    "    card = np.random.randint(1, 53)\n",
    "\n",
    "    rank = card % 13\n",
    "    is_ace = rank == 1\n",
    "    \n",
    "    if is_ace:\n",
    "        value = 11\n",
    "    elif rank >= 10:\n",
    "        value = 10\n",
    "    else:\n",
    "        value = rank\n",
    "\n",
    "    logger.debug(f\"Picked card: {value}, {is_ace}\")\n",
    "    return (value, is_ace)\n",
    "    \n",
    "def next_state(usable_ace, current_sum, next_card: Tuple[int, bool]) -> Optional[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Given the current state and next card, return next (usable_ace, current_sum) or return None if player went bust\n",
    "    \"\"\"\n",
    "    value, is_ace = next_card\n",
    "    logger.debug(f\"Old state: {usable_ace}, {current_sum}, Next card: {next_card}\")\n",
    "\n",
    "    next_sum = current_sum + value\n",
    "    next_usable_ace = usable_ace or is_ace\n",
    "    if next_sum > 21:\n",
    "        if (usable_ace or is_ace):\n",
    "            # if you already have a usable ace and you drew one, you still have one left\n",
    "            # if you only just drew one, you have none\n",
    "            # this is a XNOR operation\n",
    "            next_usable_ace = not (usable_ace ^ is_ace)\n",
    "            next_sum -= 10\n",
    "        else:\n",
    "            # went bust\n",
    "            logger.debug(\"Went Bust\")\n",
    "            return None\n",
    "    logger.debug(f\"Transitioned from state {usable_ace}, {current_sum} to {next_usable_ace}, {next_sum}\")\n",
    "    return (next_usable_ace, next_sum)\n",
    "        \n",
    "\n",
    "def player_draw_until_stick_or_bust(usable_ace, start_sum, dealer_card = None, pi = None) -> Tuple[bool, List[Tuple[bool, int]]]:\n",
    "    \"\"\"\n",
    "    Follow policy pi until stick or bust\n",
    "    Can be used by both player or dealer\n",
    "        For player usage, provide dealer_card and policy pi\n",
    "        For dealer usage, leave both as None\n",
    "    Note that dealer_card is only used in this process to select action for the player based on pi\n",
    "    Output: (end_stick, [(usable_ace, current_sum)])\n",
    "    \"\"\"\n",
    "    if pi:\n",
    "        logger.debug(\"PLAYER mode\")\n",
    "    else:\n",
    "        logger.debug(\"DEALER mode\")\n",
    "        \n",
    "    state_sequence = [(usable_ace, start_sum)]\n",
    "    while True:\n",
    "        cur_usable_ace, cur_sum = state_sequence[-1]\n",
    "        logger.debug(f\"Current step: {cur_usable_ace}, {cur_sum}\")\n",
    "        if pi:\n",
    "            # player\n",
    "            action = pi[cur_usable_ace, cur_sum-SUM_OFFSET, dealer_card]\n",
    "        else:\n",
    "            # dealer\n",
    "            if cur_sum >= 17:\n",
    "                \n",
    "                action = Action.STICK\n",
    "            else:\n",
    "                action = Action.HIT\n",
    "\n",
    "        if action == Action.STICK:\n",
    "            logger.debug(\"Sticking!\")\n",
    "            return (True, state_sequence)\n",
    "        \n",
    "        if action == Action.HIT:\n",
    "            next_card = random_card_value()\n",
    "            next_step = next_state(cur_usable_ace, cur_sum, next_card)\n",
    "            if not next_step:\n",
    "                # episode ends here\n",
    "                logger.debug(\"Went Bust!\")\n",
    "                return (False, state_sequence)\n",
    "            else:\n",
    "                state_sequence.append(next_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1a333b9-fef9-47ef-99dd-594b1926b840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 22:16:05,027 - __main__ - DEBUG - DEALER mode\n",
      "2024-11-10 22:16:05,029 - __main__ - DEBUG - Current step: False, 7\n",
      "2024-11-10 22:16:05,030 - __main__ - DEBUG - Picked card: 2, False\n",
      "2024-11-10 22:16:05,031 - __main__ - DEBUG - Old state: False, 7, Next card: (2, False)\n",
      "2024-11-10 22:16:05,032 - __main__ - DEBUG - Transitioned from state False, 7 to False, 9\n",
      "2024-11-10 22:16:05,032 - __main__ - DEBUG - Current step: False, 9\n",
      "2024-11-10 22:16:05,033 - __main__ - DEBUG - Picked card: 11, True\n",
      "2024-11-10 22:16:05,033 - __main__ - DEBUG - Old state: False, 9, Next card: (11, True)\n",
      "2024-11-10 22:16:05,034 - __main__ - DEBUG - Transitioned from state False, 9 to True, 20\n",
      "2024-11-10 22:16:05,035 - __main__ - DEBUG - Current step: True, 20\n",
      "2024-11-10 22:16:05,035 - __main__ - DEBUG - Sticking!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, [(False, 7), (False, 9), (True, 20)])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_draw_until_stick_or_bust(False, 7)\n",
    "#next_state(1, 17, (11, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9c3512-0202-4a1f-b1f3-fb3428e861ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "type State = Tuple(int, int, int)\n",
    "type Reward = int\n",
    "type Episode = List[Tuple(State, Action, Reward)]\n",
    "\n",
    "\n",
    "def generate_random_episode_ES(pi) -> Episode:\n",
    "    # generate a random starting state and action\n",
    "    usable_ace = np.random.randint(0, 2)\n",
    "    current_sum = np.random.randint(0, 10)\n",
    "    dealer_card = np.random.randint(0, 10)\n",
    "    first_action = np.random.choice(list(Action))\n",
    "\n",
    "    logger.debug(f\"Starting State: {usable_ace}, {current_sum}, {dealer_card}, {first_action}\")\n",
    "    \n",
    "    # PRE: last_state, last_action are relevant. \n",
    "    # POST: dealer either wins, \n",
    "                \n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def monte_carlo_blackjack(num_episodes=1):\n",
    "    # initial policy = HIT in all states.\n",
    "    pi = np.zeros((2, 10, 10))\n",
    "\n",
    "    # starting action-value estimates 0 for all state-action pairs\n",
    "    Q = np.zeros((2, 10, 10, 2))\n",
    "    counts = np.zeros((2, 10, 10, 2))\n",
    "\n",
    "    for i in range(num_episodes):\n",
    "        episode = generate_random_episode_ES(pi)\n",
    "\n",
    "        # keep track of first-visits to action-state pairs\n",
    "        first_visits = {}\n",
    "        for t, state_action_reward in enumerate(episode):\n",
    "            state, action, _ = state_action_reward\n",
    "            if (state, action) not in first_visits:\n",
    "                first_visits[(state, action)] = t\n",
    "        \n",
    "        G = 0\n",
    "        for t, state_action_reward in reversed(list(enumerate(episode))):\n",
    "            state, action, reward = state_action_reward\n",
    "            G = gamma*G + reward\n",
    "            \n",
    "            if t == first_visits[(state, action)]:    \n",
    "                counts[state][action] += 1\n",
    "                Q[state][action] = Q[state][action] + 1/counts[state][action]*(G - Q[state][action])\n",
    "                pi[state] = np.argmax([Q[state][0], Q[state][1]])\n",
    "\n",
    "    return pi, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0198b2-2735-40de-b767-406582d4b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = [(1, 1, 1), (2, 2, 2)]\n",
    "for t, sa in reversed(list(enumerate(episode))):\n",
    "    a, b, c = sa\n",
    "    print(t, a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2de8bc-b7ff-489b-9678-77cbdcf24a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "*(1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37ead27-3ad3-42b1-8ff1-124b61890be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6403c1-bf43-4ac5-8059-07a1e30b2061",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(list(Action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093124ed-000b-4f99-adc8-82ac10bacc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "usable_ace = 0\n",
    "is_ace = False\n",
    "not (usable_ace^is_ace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eddecc-5676-4f2c-bc0a-5c9006de79c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
